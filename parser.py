import re
import json
import requests
import socket
import time
import sys
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
from urllib.parse import quote
import requests.packages.urllib3.util.connection as urllib3_cn

# ==========================
# üîß –§–ò–ö–° –î–õ–Ø GITHUB ACTIONS (IPv4)
# ==========================
def allowed_gai_family():
    return socket.AF_INET

urllib3_cn.allowed_gai_family = allowed_gai_family

# ==========================
# ‚öôÔ∏è –ù–ê–°–¢–†–û–ô–ö–ò
# ==========================

# –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∂–∏–º EMBED (–í–∏–¥–∂–µ—Ç), –æ–Ω –ª–µ–≥—á–µ –ø–∞—Ä—Å–∏—Ç—Å—è –∏ —Ä–µ–∂–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç—Å—è
CHANNELS = [
    "https://t.me/s/Zaporizhzhyaoblenergo_news?embed=1&discussion=1",
    "https://t.me/s/info_zp?embed=1&discussion=1"
]

KEYWORDS = [
    "–ì–ü–í", "–ì–†–ê–§–Ü–ö", "–í–Ü–î–ö–õ–Æ–ß–ï–ù", "–ï–õ–ï–ö–¢–†–û", "–ß–ï–†–ì", 
    "–û–ù–û–í–õ–ï–ù", "–ó–ú–Ü–ù", "–û–ë–õ–ï–ù–ï–†–ì–û", "–£–ö–†–ï–ù–ï–†–ì–û", "–°–í–Ü–¢–õ"
]

UA_MONTHS = {
    "–°–Ü–ß–ù–Ø": 1, "–õ–Æ–¢–û–ì–û": 2, "–ë–ï–†–ï–ó–ù–Ø": 3, "–ö–í–Ü–¢–ù–Ø": 4, "–¢–†–ê–í–ù–Ø": 5, "–ß–ï–†–í–ù–Ø": 6,
    "–õ–ò–ü–ù–Ø": 7, "–°–ï–†–ü–ù–Ø": 8, "–í–ï–†–ï–°–ù–Ø": 9, "–ñ–û–í–¢–ù–Ø": 10, "–õ–ò–°–¢–û–ü–ê–î–ê": 11, "–ì–†–£–î–ù–Ø": 12
}
UA_MONTHS_REVERSE = {v: k for k, v in UA_MONTHS.items()}

# ==========================
# üõ† –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
# ==========================

def get_kiev_time():
    return datetime.utcnow() + timedelta(hours=2)

def log(msg):
    print(msg)
    sys.stdout.flush()

def get_html(target_url):
    # –°–ø–∏—Å–æ–∫ –ø—Ä–æ–∫—Å–∏. allorigins —á–∞—Å—Ç–æ –ª—É—á—à–µ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å —Ç–µ–∫—Å—Ç–æ–º
    proxies = [
        f"https://api.allorigins.win/raw?url={quote(target_url)}",
        f"https://corsproxy.io/?{quote(target_url)}",
        f"https://api.codetabs.com/v1/proxy?quest={quote(target_url)}"
    ]

    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }

    for url in proxies:
        try:
            log(f"   üîÑ –ü—Ä–æ–±—É–µ–º —á–µ—Ä–µ–∑: {url[:40]}...")
            response = requests.get(url, headers=headers, timeout=20)
            
            if response.status_code == 200 and len(response.text) > 500:
                log(f"   ‚úÖ –°–∫–∞—á–∞–Ω–æ {len(response.text)} –±–∞–π—Ç.")
                return response.text
            else:
                log(f"   ‚ö†Ô∏è –ù–µ—É–¥–∞—á–Ω–æ (–ö–æ–¥: {response.status_code}, –†–∞–∑–º–µ—Ä: {len(response.text)})")
                
        except Exception as e:
            log(f"   ‚ùå –û—à–∏–±–∫–∞: {str(e)[:50]}...")
        
        time.sleep(1)

    return None

def parse_channel(url):
    html = get_html(url)
    if not html: return []

    soup = BeautifulSoup(html, 'html.parser')
    
    # === DEBUG INFO (–ß–¢–û–ë–´ –ü–û–ù–Ø–¢–¨, –ß–¢–û –°–ö–ê–ß–ê–õ–û–°–¨) ===
    page_title = soup.title.string.strip() if soup.title else "–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞"
    log(f"   üîé –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: '{page_title}'")
    
    # –ò—â–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è. –í embed-—Ä–µ–∂–∏–º–µ –∫–ª–∞—Å—Å—ã –º–æ–≥—É—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è, –∏—â–µ–º —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ
    # –û–±—ã—á–Ω–æ —ç—Ç–æ tgme_widget_message_text –∏–ª–∏ js-message_text
    message_divs = soup.find_all('div', class_=re.compile(r'(tgme_widget_message_text|js-message_text)'))
    
    log(f"   üîé –ù–∞–π–¥–µ–Ω–æ –±–ª–æ–∫–æ–≤ —Å —Ç–µ–∫—Å—Ç–æ–º: {len(message_divs)}")
    
    if len(message_divs) == 0:
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –≤—ã–≤–æ–¥–∏–º –∫—É—Å–æ—á–µ–∫ HTML –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        log("   ‚ö†Ô∏è HTML (–ø–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤):")
        log(f"   {str(soup)[:200]}")
        return []

    found_schedules = []

    months_regex = "|".join(UA_MONTHS.keys())
    date_pattern = re.compile(rf"(\d{{1,2}})\s+({months_regex})", re.IGNORECASE)
    time_pattern = re.compile(r"(\d{1,2}[:.]\d{2})\s*[-‚Äì‚Äî‚àí]\s*(\d{1,2}[:.]\d{2})")
    specific_queue_pattern = re.compile(r"\b([1-6]\.[12])\b")

    # –ò—â–µ–º timestamps –æ—Ç–¥–µ–ª—å–Ω–æ, —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∏ –≤ –¥—Ä—É–≥–∏—Ö –±–ª–æ–∫–∞—Ö
    # –í Embed —Ä–µ–∂–∏–º–µ timestamp –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ª–æ–∂–Ω–µ–µ –¥–æ—Å—Ç–∞—Ç—å, –ø–æ—ç—Ç–æ–º—É –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞—Ç—É –ø–æ—Å—Ç–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞
    
    # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–≤—ã–º –±–ª–æ–∫–∞–º
    for text_div in message_divs:
        text = text_div.get_text(separator="\n")

        if not any(k in text.upper() for k in KEYWORDS):
            continue

        # –í Embed —Ä–µ–∂–∏–º–µ –¥–∞—Ç—É –ø–æ—Å—Ç–∞ —Å–ª–æ–∂–Ω–æ –¥–æ—Å—Ç–∞—Ç—å –∏–∑ HTML, –±–µ—Ä–µ–º —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É
        # –ù–æ –µ—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å –¥–∞—Ç–∞ (25 –ì–†–£–î–ù–Ø) - —ç—Ç–æ –Ω–∞—Å —Å–ø–∞—Å–µ—Ç
        
        # –≠–º—É–ª—è—Ü–∏—è timestamp (–±–µ—Ä–µ–º —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è, –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏)
        # –í –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ —Å–ª—É—á–∞–µ–≤ –Ω–∞–º –≤–∞–∂–Ω–∞ –¥–∞—Ç–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å–æ–æ–±—â–µ–Ω–∏—è
        post_timestamp = datetime.utcnow().isoformat() 

        lines = [line.strip().replace('\xa0', ' ') for line in text.split('\n') if line.strip()]
        
        explicit_date_key = None
        updated_at_val = None
        queues_found = {}

        for line in lines:
            if not explicit_date_key:
                match = date_pattern.search(line)
                if match:
                    day, month = match.groups()
                    explicit_date_key = f"{day} {month.upper()}"

            if not updated_at_val:
                time_upd_match = re.search(r"\(–æ–Ω–æ–≤–ª–µ–Ω–æ.*(\d{2}:\d{2})\)", line, re.IGNORECASE)
                if time_upd_match:
                    updated_at_val = time_upd_match.group(1)

            time_matches = list(time_pattern.finditer(line))
            
            if time_matches:
                intervals = []
                for tm in time_matches:
                    start, end = tm.groups()
                    start = start.replace('.', ':')
                    end = end.replace('.', ':')
                    intervals.append({"start": start, "end": end})

                text_before_time = line[:time_matches[0].start()]
                found_sub_queues = specific_queue_pattern.findall(text_before_time)
                
                for q_id in found_sub_queues:
                    if q_id not in queues_found:
                        queues_found[q_id] = []
                    queues_found[q_id].extend(intervals)

        if queues_found:
            # –ß–∏—Å—Ç–∫–∞ –¥—É–±–ª–µ–π
            for q_id in queues_found:
                unique_intervals = []
                seen = set()
                for interval in queues_found[q_id]:
                    key = f"{interval['start']}-{interval['end']}"
                    if key not in seen:
                        seen.add(key)
                        unique_intervals.append(interval)
                unique_intervals.sort(key=lambda x: x['start'])
                queues_found[q_id] = unique_intervals

            final_date_key = None

            if explicit_date_key:
                final_date_key = explicit_date_key
            else:
                # –ï—Å–ª–∏ –¥–∞—Ç—ã –≤ —Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç, –ø—Ä–æ–±—É–µ–º —É–≥–∞–¥–∞—Ç—å –ø–æ —Å–ª–æ–≤—É "–ó–∞–≤—Ç—Ä–∞"
                # –û–ø–∏—Ä–∞–µ–º—Å—è –Ω–∞ "—Å–µ–π—á–∞—Å" + —Å–º–µ—â–µ–Ω–∏–µ
                now_kiev = get_kiev_time()
                if "–∑–∞–≤—Ç—Ä–∞" in text.lower():
                    target_date = now_kiev + timedelta(days=1)
                    log(f"‚ÑπÔ∏è –ù–∞–π–¥–µ–Ω –≥—Ä–∞—Ñ–∏–∫ –Ω–∞ –ó–ê–í–¢–†–ê (–ø–æ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É).")
                else:
                    target_date = now_kiev
                
                day = target_date.day
                month_name = UA_MONTHS_REVERSE.get(target_date.month, "–ì–†–£–î–ù–Ø")
                final_date_key = f"{day} {month_name}"

            if not updated_at_val:
                updated_at_val = get_kiev_time().strftime("%H:%M")

            found_schedules.append({
                "date": final_date_key,
                "queues": queues_found,
                "updated_at": updated_at_val,
                "source_ts": post_timestamp
            })

    return found_schedules

def merge_schedules(all_schedules):
    merged = {}
    for sch in all_schedules:
        d_key = sch['date']
        # –ü—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–º –Ω–∞–π–¥–µ–Ω–Ω—ã–º (—Ç–∞–∫ –∫–∞–∫ source_ts –≤ embed –Ω–µ –Ω–∞–¥–µ–∂–µ–Ω)
        # –ù–æ –ø–æ—Å–∫–æ–ª—å–∫—É –º—ã –∏–¥–µ–º –ø–æ –ª–µ–Ω—Ç–µ, –ø–æ—Å–ª–µ–¥–Ω–∏–µ –ø–æ—Å—Ç—ã –æ–±—ã—á–Ω–æ –∞–∫—Ç—É–∞–ª—å–Ω–µ–µ
        merged[d_key] = sch
    return list(merged.values())

def main():
    all_found = []
    
    for url in CHANNELS:
        log(f"üì° –ü–∞—Ä—Å–∏–Ω–≥ –∫–∞–Ω–∞–ª–∞: {url}")
        res = parse_channel(url)
        if res:
            log(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ –≥—Ä–∞—Ñ–∏–∫–æ–≤: {len(res)}")
            all_found.extend(res)
        else:
            log("   ‚ùå –ì—Ä–∞—Ñ–∏–∫–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")

    final_list = merge_schedules(all_found)

    # === –ü–†–ï–î–û–•–†–ê–ù–ò–¢–ï–õ–¨ ===
    if not final_list:
        log("\n‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –ü–∞—Ä—Å–µ—Ä –Ω–µ –Ω–∞—à–µ–ª –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö.")
        log("‚ö†Ô∏è –§–∞–π–ª schedule.json –ù–ï –ë–£–î–ï–¢ –ò–ó–ú–ï–ù–ï–ù, —á—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä—É—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.")
        return
    # =======================

    def date_sorter(item):
        try:
            parts = item['date'].split()
            day = int(parts[0])
            month_str = parts[1]
            month = UA_MONTHS.get(month_str, 0)
            now = datetime.now()
            year = now.year
            if now.month == 12 and month == 1: year += 1
            elif now.month == 1 and month == 12: year -= 1
            return datetime(year, month, day)
        except:
            return datetime.now()

    final_list.sort(key=date_sorter)
    final_list = final_list[-3:]

    output_json = {
        "last_check": get_kiev_time().strftime("%d.%m %H:%M"),
        "schedules": final_list
    }

    # –ß–∏—Å—Ç–∏–º —Å–ª—É–∂–µ–±–Ω—ã–µ –ø–æ–ª—è
    for item in output_json["schedules"]:
        if "source_ts" in item:
            del item["source_ts"]

    with open('schedule.json', 'w', encoding='utf-8') as f:
        json.dump(output_json, f, ensure_ascii=False, indent=4)
        
    log(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(final_list)} –¥–Ω–µ–π –≤ schedule.json")

if __name__ == "__main__":
    main()
