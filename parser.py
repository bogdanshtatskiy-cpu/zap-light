import re
import json
import requests
import socket
import time
import sys
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
from urllib.parse import quote

# ==========================
# ‚öôÔ∏è –ù–ê–°–¢–†–û–ô–ö–ò
# ==========================

CHANNELS = [
    "https://t.me/s/Zaporizhzhyaoblenergo_news",
    "https://t.me/s/info_zp"
]

KEYWORDS = [
    "–ì–ü–í", "–ì–†–ê–§–Ü–ö", "–í–Ü–î–ö–õ–Æ–ß–ï–ù", "–ï–õ–ï–ö–¢–†–û", "–ß–ï–†–ì", 
    "–û–ù–û–í–õ–ï–ù", "–ó–ú–Ü–ù", "–û–ë–õ–ï–ù–ï–†–ì–û", "–£–ö–†–ï–ù–ï–†–ì–û", "–°–í–Ü–¢–õ"
]

UA_MONTHS = {
    "–°–Ü–ß–ù–Ø": 1, "–õ–Æ–¢–û–ì–û": 2, "–ë–ï–†–ï–ó–ù–Ø": 3, "–ö–í–Ü–¢–ù–Ø": 4, "–¢–†–ê–í–ù–Ø": 5, "–ß–ï–†–í–ù–Ø": 6,
    "–õ–ò–ü–ù–Ø": 7, "–°–ï–†–ü–ù–Ø": 8, "–í–ï–†–ï–°–ù–Ø": 9, "–ñ–û–í–¢–ù–Ø": 10, "–õ–ò–°–¢–û–ü–ê–î–ê": 11, "–ì–†–£–î–ù–Ø": 12
}
UA_MONTHS_REVERSE = {v: k for k, v in UA_MONTHS.items()}

# ==========================
# üõ† –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
# ==========================

def get_kiev_time():
    return datetime.utcnow() + timedelta(hours=2)

def log(msg):
    print(msg)
    sys.stdout.flush()

def get_html(target_url):
    """
    –°–∫–∞—á–∏–≤–∞–µ—Ç HTML —á–µ—Ä–µ–∑ –≤–µ–±-–ø—Ä–æ–∫—Å–∏, —á—Ç–æ–±—ã –æ–±–æ–π—Ç–∏ –±–∞–Ω IP GitHub —Å–æ —Å—Ç–æ—Ä–æ–Ω—ã Telegram.
    """
    # –°–ø–∏—Å–æ–∫ –∑–µ—Ä–∫–∞–ª/–ø—Ä–æ–∫—Å–∏ –¥–ª—è –æ–±—Ö–æ–¥–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
    # –ú—ã –∫–æ–¥–∏—Ä—É–µ–º URL, —á—Ç–æ–±—ã –ø–µ—Ä–µ–¥–∞—Ç—å –µ–≥–æ –∫–∞–∫ –ø–∞—Ä–∞–º–µ—Ç—Ä
    proxies = [
        # –í–∞—Ä–∏–∞–Ω—Ç 1: corsproxy.io (–æ–±—ã—á–Ω–æ —Å–∞–º—ã–π –±—ã—Å—Ç—Ä—ã–π)
        f"https://corsproxy.io/?{quote(target_url)}",
        # –í–∞—Ä–∏–∞–Ω—Ç 2: codetabs (—Ä–µ–∑–µ—Ä–≤)
        f"https://api.codetabs.com/v1/proxy?quest={quote(target_url)}",
        # –í–∞—Ä–∏–∞–Ω—Ç 3: –ü—Ä—è–º–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ (–Ω–∞ —Å–ª—É—á–∞–π, –µ—Å–ª–∏ –∑–∞–ø—É—â–µ–Ω–æ –ª–æ–∫–∞–ª—å–Ω–æ, –∞ –Ω–µ –Ω–∞ GitHub)
        target_url
    ]

    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/120.0.0.0 Safari/537.36'
    }

    for url in proxies:
        is_direct = (url == target_url)
        prefix = "DIRECT" if is_direct else "PROXY"
        
        try:
            log(f"   üîÑ [{prefix}] –ó–∞–ø—Ä–æ—Å –∫: {target_url}...")
            
            # –¢–∞–π–º-–∞—É—Ç 15 —Å–µ–∫
            response = requests.get(url, headers=headers, timeout=15)
            
            if response.status_code == 200 and len(response.text) > 1000:
                log("   ‚úÖ –£—Å–ø–µ—à–Ω–æ!")
                return response.text
            else:
                log(f"   ‚ö†Ô∏è –ù–µ—É–¥–∞—á–Ω–æ (Status: {response.status_code}, Len: {len(response.text)})")
                
        except Exception as e:
            log(f"   ‚ùå –û—à–∏–±–∫–∞: {str(e)[:50]}...")
        
        # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –ø–æ–ø—ã—Ç–∫–æ–π
        time.sleep(1)

    log("   ‚õî –í—Å–µ –º–µ—Ç–æ–¥—ã –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏.")
    return None

def parse_channel(url):
    html = get_html(url)
    if not html: return []

    soup = BeautifulSoup(html, 'html.parser')
    message_wraps = soup.find_all('div', class_='tgme_widget_message_wrap')
    
    found_schedules = []

    months_regex = "|".join(UA_MONTHS.keys())
    date_pattern = re.compile(rf"(\d{{1,2}})\s+({months_regex})", re.IGNORECASE)
    
    # –í—Ä–µ–º—è: "00:00 - 04:00"
    time_pattern = re.compile(r"(\d{1,2}[:.]\d{2})\s*[-‚Äì‚Äî‚àí]\s*(\d{1,2}[:.]\d{2})")
    
    # –¢–æ–ª—å–∫–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –æ—á–µ—Ä–µ–¥–∏ (1.1, 2.1). –ì—Ä—É–ø–ø "1" –±–æ–ª—å—à–µ –Ω–µ—Ç.
    specific_queue_pattern = re.compile(r"\b([1-6]\.[12])\b")

    for wrap in reversed(message_wraps):
        text_div = wrap.find('div', class_='tgme_widget_message_text')
        if not text_div: continue
        text = text_div.get_text(separator="\n")

        if not any(k in text.upper() for k in KEYWORDS):
            continue

        time_tag = wrap.find('time')
        post_timestamp = ""
        if time_tag and time_tag.has_attr('datetime'):
            post_timestamp = time_tag['datetime']
        else:
            continue

        lines = [line.strip().replace('\xa0', ' ') for line in text.split('\n') if line.strip()]
        
        explicit_date_key = None
        updated_at_val = None
        queues_found = {}

        # --- –ê–ù–ê–õ–ò–ó –°–¢–†–û–ö ---
        for line in lines:
            if not explicit_date_key:
                match = date_pattern.search(line)
                if match:
                    day, month = match.groups()
                    explicit_date_key = f"{day} {month.upper()}"

            if not updated_at_val:
                time_upd_match = re.search(r"\(–æ–Ω–æ–≤–ª–µ–Ω–æ.*(\d{2}:\d{2})\)", line, re.IGNORECASE)
                if time_upd_match:
                    updated_at_val = time_upd_match.group(1)

            # –ò—â–µ–º –≤—Ä–µ–º—è
            time_matches = list(time_pattern.finditer(line))
            
            if time_matches:
                intervals = []
                for tm in time_matches:
                    start, end = tm.groups()
                    start = start.replace('.', ':')
                    end = end.replace('.', ':')
                    intervals.append({"start": start, "end": end})

                # –ò—â–µ–º –æ—á–µ—Ä–µ–¥–∏ –¢–û–õ–¨–ö–û –≤ —Ç–µ–∫—Å—Ç–µ –ü–ï–†–ï–î –≤—Ä–µ–º–µ–Ω–µ–º
                text_before_time = line[:time_matches[0].start()]
                
                # –ò—â–µ–º 1.1, 1.2...
                found_sub_queues = specific_queue_pattern.findall(text_before_time)
                
                # –ü—Ä–∏–≤—è–∑—ã–≤–∞–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã –∫ –Ω–∞–π–¥–µ–Ω–Ω—ã–º –æ—á–µ—Ä–µ–¥—è–º
                for q_id in found_sub_queues:
                    if q_id not in queues_found:
                        queues_found[q_id] = []
                    queues_found[q_id].extend(intervals)

        # --- –°–û–•–†–ê–ù–ï–ù–ò–ï ---
        if queues_found:
            # === –û–ß–ò–°–¢–ö–ê –î–£–ë–õ–ò–ö–ê–¢–û–í ===
            for q_id in queues_found:
                unique_intervals = []
                seen = set()
                for interval in queues_found[q_id]:
                    key = f"{interval['start']}-{interval['end']}"
                    if key not in seen:
                        seen.add(key)
                        unique_intervals.append(interval)
                unique_intervals.sort(key=lambda x: x['start'])
                queues_found[q_id] = unique_intervals
            # ==========================

            final_date_key = None

            if explicit_date_key:
                final_date_key = explicit_date_key
            else:
                try:
                    dt = datetime.fromisoformat(post_timestamp.replace('Z', '+00:00'))
                    dt_kiev = dt + timedelta(hours=2)

                    if "–∑–∞–≤—Ç—Ä–∞" in text.lower():
                        dt_kiev += timedelta(days=1)
                        log(f"‚ÑπÔ∏è –ú–∞—Ä–∫–µ—Ä '–∑–∞–≤—Ç—Ä–∞'. –î–∞—Ç–∞ —Å–º–µ—â–µ–Ω–∞: {dt_kiev.strftime('%d.%m')}")

                    day = dt_kiev.day
                    month_name = UA_MONTHS_REVERSE.get(dt_kiev.month, "–ì–†–£–î–ù–Ø")
                    final_date_key = f"{day} {month_name}"
                except Exception as e:
                    log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –¥–∞—Ç—ã: {e}")
                    continue

            if not updated_at_val:
                try:
                    dt = datetime.fromisoformat(post_timestamp.replace('Z', '+00:00'))
                    dt_kiev = dt + timedelta(hours=2)
                    updated_at_val = dt_kiev.strftime("%H:%M")
                except:
                    updated_at_val = "??:??"

            found_schedules.append({
                "date": final_date_key,
                "queues": queues_found,
                "updated_at": updated_at_val,
                "source_ts": post_timestamp
            })

    return found_schedules

def merge_schedules(all_schedules):
    merged = {}
    for sch in all_schedules:
        d_key = sch['date']
        if d_key not in merged:
            merged[d_key] = sch
        else:
            existing_ts = merged[d_key]['source_ts']
            new_ts = sch['source_ts']
            if new_ts > existing_ts:
                log(f"üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ {d_key} (–Ω–∞–π–¥–µ–Ω –±–æ–ª–µ–µ —Å–≤–µ–∂–∏–π –ø–æ—Å—Ç).")
                merged[d_key] = sch
    return list(merged.values())

def main():
    all_found = []
    
    for url in CHANNELS:
        log(f"üì° –ü–∞—Ä—Å–∏–Ω–≥ –∫–∞–Ω–∞–ª–∞: {url}")
        res = parse_channel(url)
        log(f"   –ù–∞–π–¥–µ–Ω–æ –≥—Ä–∞—Ñ–∏–∫–æ–≤: {len(res)}")
        all_found.extend(res)

    final_list = merge_schedules(all_found)

    def date_sorter(item):
        try:
            parts = item['date'].split()
            day = int(parts[0])
            month_str = parts[1]
            month = UA_MONTHS.get(month_str, 0)
            now = datetime.now()
            year = now.year
            if now.month == 12 and month == 1: year += 1
            elif now.month == 1 and month == 12: year -= 1
            return datetime(year, month, day)
        except:
            return datetime.now()

    final_list.sort(key=date_sorter)
    final_list = final_list[-3:]

    output_json = {
        "last_check": get_kiev_time().strftime("%d.%m %H:%M"),
        "schedules": final_list
    }

    for item in output_json["schedules"]:
        if "source_ts" in item:
            del item["source_ts"]

    with open('schedule.json', 'w', encoding='utf-8') as f:
        json.dump(output_json, f, ensure_ascii=False, indent=4)
        
    log(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(final_list)} –¥–Ω–µ–π –≤ schedule.json")

if __name__ == "__main__":
    main()
